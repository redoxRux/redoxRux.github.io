---
layout: post
title:  "why study ai"
date:   2025-10-25 16:00:00 +0000
categories: thoughts ai
---

I had real interest in AI. Then LLMs exploded and I lost it completely.

## The Problem

Before the LLM boom, AI meant something different. Understanding intelligence. Building minds that think. Deep questions about consciousness, reasoning, learning. Elegant algorithms capturing something profound.

Then ChatGPT happened. Suddenly everyone's an "AI engineer" for calling APIs. Billions of dollars. Closed models. Corporate control. The questions I cared about buried under hype.

Now studying AI feels like surrendering to the corporate machine instead of pursuing genuine curiosity.

## What Got Hijacked

My interest wasn't in language models. It was in intelligence itself. How does a mind work? Can consciousness emerge from computation? What is thinking, really?

LLMs became "AI" and everything else disappeared from conversation. The genuine scientific questions got replaced by product demos and marketing.

I'm not demotivated about the technology. I'm demotivated about what it became.

## The Money Problem

Only large companies control the cutting edge. OpenAI, Google, Meta. Billions in compute. Closed research. It feels like only money matters, nothing else.

The most interesting work isn't at these companies though. It's in open source projects, individual researchers with unique approaches, problems the big companies ignore. Geohot built tinygrad not to compete with PyTorch, but to understand neural networks from first principles.

Corporate dominance is mostly in deployment, not innovation. Real advancement comes from understanding fundamentals, novel architectures, research without immediate commercial value.

## The Real Question

Should I study LLMs to catch up? No. That's the wrong frame.

The question is: do I want to understand how intelligence works?

If yes, LLMs are currently the best window into that question, regardless of who controls the big models. They reveal how pattern recognition works, how knowledge gets encoded, how reasoning emerges from statistics.

Not because they're hyped. Because they're genuine puzzles about the nature of thought.

## What Actually Matters

Study by implementation, not usage. Build a transformer from scratch. Implement attention mechanisms. Train small models on interesting datasets. Experiment with novel architectures.

This isn't about competing with OpenAI. It's about understanding intelligence.

The genuine AI research is still happening. Consciousness and self-awareness in machines. How cognition emerges from computation. Novel architectures that think differently. Understanding intelligence from first principles.

Scientists doing this work don't care about ChatGPT either.

## The Real Conflict

I want to reconnect with the AI that matters. The questions that made me interested in the first place. Before the hype, before the corporate takeover.

How does a mind work? Can consciousness emerge from computation? What is intelligence, really? How do you build something that truly thinks?

LLMs might be relevant to these questions. Or they might not. But the questions themselves are eternal.

My real interest didn't disappear. It got buried under frustration and corporate bullshit. The challenge is finding the path back to genuine curiosity.

The AI I care about still exists. It's just not trending on Twitter.